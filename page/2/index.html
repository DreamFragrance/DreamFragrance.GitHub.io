<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
<meta property="og:type" content="website">
<meta property="og:title" content="紫梦沁香">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="紫梦沁香">
<meta property="og:description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="紫梦沁香">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>紫梦沁香</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6bc20780b9c032635241d71c52b76953";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<script type="text/javascript" src="/js/game/modernizr.custom.js"></script>

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">紫梦沁香</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-game">

    <a href="/game/" rel="section"><i class="fa fa-gamepad fa-fw"></i>游戏</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/" class="post-title-link" itemprop="url">Pandas熊猫养殖</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-23 17:57:21" itemprop="dateCreated datePublished" datetime="2021-10-23T17:57:21+08:00">2021-10-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-24 17:16:49" itemprop="dateModified" datetime="2021-11-24T17:16:49+08:00">2021-11-24</time>
              </span>

          
            <span id="/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/" class="post-meta-item leancloud_visitors" data-flag-title="Pandas熊猫养殖" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="一、Pandas-概览"><a href="#一、Pandas-概览" class="headerlink" title="一、Pandas 概览"></a>一、Pandas 概览</h2><h4 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h4><p><strong>Pandas</strong> 是 Python 的核心数据分析支持库，提供了快速、灵活、明确的数据结构，旨在简单、直观地处理关系型、标记型数据。</p>
<p>Pandas 适用于处理以下类型的数据：</p>
<ul>
<li>与 SQL 或 Excel 表类似的，含异构列的表格数据;</li>
<li>有序和无序（非固定频率）的时间序列数据;</li>
<li>带行列标签的矩阵数据，包括同构或异构型数据;</li>
<li>任意其它形式的观测、统计数据集, 数据转入 Pandas 数据结构时不必事先标记。</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/10/23/Pandas%E7%86%8A%E7%8C%AB%E5%85%BB%E6%AE%96/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/18/Mybatis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/18/Mybatis/" class="post-title-link" itemprop="url">Mybatis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-18 16:44:08" itemprop="dateCreated datePublished" datetime="2021-10-18T16:44:08+08:00">2021-10-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-12-11 00:43:45" itemprop="dateModified" datetime="2021-12-11T00:43:45+08:00">2021-12-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SSM/" itemprop="url" rel="index"><span itemprop="name">SSM</span></a>
                </span>
            </span>

          
            <span id="/2021/10/18/Mybatis/" class="post-meta-item leancloud_visitors" data-flag-title="Mybatis" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/18/Mybatis/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/18/Mybatis/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><h4 id="1-1、什么是Mybatis"><a href="#1-1、什么是Mybatis" class="headerlink" title="1.1、什么是Mybatis"></a>1.1、什么是Mybatis</h4><ul>
<li>MyBatis 是一款优秀的持久层框架。</li>
<li>它支持自定义 SQL、存储过程以及高级映射。</li>
<li>MyBatis 免除了几乎所有的 JDBC 代码以及设置参数和获取结果集的工作。</li>
<li>MyBatis 可以通过简单的 XML 或注解来配置和映射原始类型、接口和 Java POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。</li>
<li>MyBatis 本是apache的一个开源项目 iBatis。</li>
<li>2010年这个项目由 apache software foundation 迁移到了 google code，并且改名为MyBatis。</li>
<li>2013年11月迁移到 Github。</li>
</ul>
<p>如何获取 Mybatis？</p>
<ul>
<li><p>maven 仓库：</p>
<figure class="highlight xml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.mybatis<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.5.7<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>Github：<a target="_blank" rel="noopener" href="https://github.com/search?q=Mybatis">https://github.com/search?q=Mybatis</a></p>
</li>
<li><p>中文文档：<a target="_blank" rel="noopener" href="https://mybatis.net.cn/">https://mybatis.net.cn/</a></p>
</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/10/18/Mybatis/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/17/%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/17/%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88/" class="post-title-link" itemprop="url">降低过拟合</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-17 15:32:10" itemprop="dateCreated datePublished" datetime="2021-10-17T15:32:10+08:00">2021-10-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-19 19:48:05" itemprop="dateModified" datetime="2021-10-19T19:48:05+08:00">2021-10-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span id="/2021/10/17/%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88/" class="post-meta-item leancloud_visitors" data-flag-title="降低过拟合" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/17/%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/17/%E9%99%8D%E4%BD%8E%E8%BF%87%E6%8B%9F%E5%90%88/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>在训练模型的过程中，过拟合几乎是不可避免的。因此可以这么说，深度学习就是训练一个庞大的模型，在此基础上我们来降低过拟合的程度。相较之下，如果模型欠拟合了，貌似除了扩大模型就没有任何方法了。</p>
<p>下面介绍几个常用的降低过拟合的方法。</p>
<h2 id="一、正则化"><a href="#一、正则化" class="headerlink" title="一、正则化"></a>一、正则化</h2><h4 id="1-什么是正则化？"><a href="#1-什么是正则化？" class="headerlink" title="1. 什么是正则化？"></a>1. 什么是正则化？</h4><p>正则化的思想，即通过<code>限制</code>参数值的选择范围来控制模型容量。而正则化又分为岭回归（权重衰退）、LASSO 回归和弹性网络等。下面我着重说明的是岭回归。</p>
<p>首先，先来看一张极度过拟合的图像。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5tSi5t.png" alt=""></p>
<p>这是上述图像的部分权重，无一例外，每个 $W_i$ 都极其的大，这也导致了图像十分的<code>陡峭</code>。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">array([-<span class="number">4.09493627e+11</span>,  <span class="number">5.76349998e+12</span>,  <span class="number">1.71369179e+11</span>, -<span class="number">9.99031499e+12</span>,</span><br><span class="line">        <span class="number">9.23500127e+11</span>,  <span class="number">9.26094018e+12</span>, -<span class="number">1.94635409e+12</span>, -<span class="number">5.40895631e+10</span>,</span><br><span class="line">        <span class="number">7.94601628e+11</span>, -<span class="number">7.85418293e+12</span>,  <span class="number">1.63904594e+12</span>,  <span class="number">1.67984971e+12</span>,</span><br><span class="line">       -<span class="number">9.87156668e+11</span>,  <span class="number">6.88721582e+12</span>, -<span class="number">1.64914180e+12</span>,  <span class="number">3.50775793e+11</span>,</span><br><span class="line">        <span class="number">2.60751888e+11</span>, -<span class="number">5.87372086e+12</span>,  <span class="number">1.66748622e+12</span>, -<span class="number">3.77434047e+12</span>,</span><br><span class="line">        <span class="number">1.00605169e+12</span>,  <span class="number">2.34190394e+12</span>, -<span class="number">8.57867266e+11</span>,  <span class="number">5.39077331e+12</span>,</span><br><span class="line">       -<span class="number">1.60621032e+12</span>,  <span class="number">2.95930952e+12</span>, -<span class="number">9.52432067e+11</span>, -<span class="number">1.74889800e+12</span>])</span><br></pre></td></tr></tbody></table></figure>
<p>因此很自然而然地就能想到，那我限制 $W_i$ 的选择范围就行了嘛。从模型的角度来说，参数数量不变，但参数的选择范围小了，那模型自然也变小了。</p>
<p>于是就有了使用均方范数作为<code>硬性</code>限制，小的 θ 意味着更强的正则项。</p>
<p>需要注意的是，偏置 <strong>b</strong> 并没有加入到正则化中来，毕竟我们的目标是让曲线更加的<code>平缓</code>，跟偏置 <strong>b</strong> 没有什么关系。</p>
<p>$min l(w,b) \quad subject\ to \quad ||W||^2 \le θ,\quad\quad ||W||^2 = \sum W^2$</p>
<p>但硬性限制优化求导比较麻烦，结果也会比较<code>硬</code>，一般使用均方范数作为<code>柔性</code>限制。</p>
<p>$loss = l(w, b) + \frac{λ}{2}||W||^2$</p>
<p>其中超参数 λ 控制了正则项的重要程度</p>
<ul>
<li>λ = 0，即无正则化，和普通的损失函数没有区别。</li>
<li>λ → $\infty$，此时 W → <strong>0</strong></li>
</ul>
<h4 id="2-如何影响损失函数？"><a href="#2-如何影响损失函数？" class="headerlink" title="2. 如何影响损失函数？"></a>2. 如何影响损失函数？</h4><p>可以看到，原先的极值点 $\widetilde{W}^*$ 在绿色椭圆的圆心，但在加入正则化项之后，极值点在两者之间做了一个权衡，取在了切点。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5tFpqS.png" alt=""></p>
<h4 id="3-参数更新法则"><a href="#3-参数更新法则" class="headerlink" title="3. 参数更新法则"></a>3. 参数更新法则</h4><ul>
<li><p>计算梯度</p>
<p>$\frac{\partial}{\partial W}(l(W, b) + \frac{λ}{2}||W||^2) = \frac{\partial l(W, b)}{\partial W} + λW$</p>
</li>
<li><p>更新参数</p>
<p>$W’ = W - η(\frac{\partial l(W, b)}{\partial W} + λW) = (1 - ηλ)W - η\frac{\partial l(W, b)}{\partial W}$</p>
</li>
</ul>
<p>通常 ηλ &lt; 1，因此每次在参数更新时，都会对 W 进行<code>缩小</code>，也就是权重衰退这个名字的由来。</p>
<h4 id="4-岭回归"><a href="#4-岭回归" class="headerlink" title="4. 岭回归"></a>4. 岭回归</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">RidgeRegression</span>(<span class="params">degree,alpha</span>):</span></span><br><span class="line">    pipeline = Pipeline([</span><br><span class="line">        (<span class="string">"poly"</span>,PolynomialFeatures(degree = degree)),</span><br><span class="line">        (<span class="string">"std_scaler"</span>,StandardScaler()),</span><br><span class="line">        (<span class="string">"ridge_reg"</span>,Ridge(alpha=alpha))</span><br><span class="line">    ])</span><br><span class="line">    <span class="keyword">return</span> pipeline</span><br></pre></td></tr></tbody></table></figure>
<p>alpha = 0，即普通多项式回归。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UMrqJ.png" alt=""></p>
<p>alpha = 1e-4，曲线一下子就柔和了。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UQeL4.png" alt=""></p>
<p>alpha = 100，有点像二次曲线了。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UQJyD.png" alt=""></p>
<p>alpha → $\infty$，为了控制损失函数，只能将权重设为0。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UQhYq.png" alt=""></p>
<h4 id="5-Tensorflow-岭回归实现"><a href="#5-Tensorflow-岭回归实现" class="headerlink" title="5. Tensorflow 岭回归实现"></a>5. Tensorflow 岭回归实现</h4><p>为了能够过拟合，只设置了20个训练样本，每个样本有 200 个特征。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">n_train = <span class="number">20</span></span><br><span class="line">n_test = <span class="number">100</span></span><br><span class="line">num_inputs = <span class="number">200</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">num_outputs = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">true_w, true_b = tf.ones([num_inputs, <span class="number">1</span>]) * <span class="number">0.01</span>, <span class="number">0.05</span></span><br><span class="line">train_data = d2l.synthetic_data(true_w, true_b, n_train)</span><br><span class="line">test_data = d2l.synthetic_data(true_w, true_b, n_test)</span><br><span class="line">train_iter = d2l.load_array(train_data, batch_size)</span><br><span class="line">test_iter = d2l.load_array(test_data, batch_size, is_train=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>参数初始化，线性模型没那么多讲究，初始化为0也行。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_params</span>(<span class="params">num_inputs, num_outputs</span>):</span></span><br><span class="line">    W = tf.Variable(tf.random.normal(mean=<span class="number">1</span>, shape=(num_inputs, <span class="number">1</span>)))</span><br><span class="line">    b = tf.Variable(tf.zeros(num_outputs))</span><br><span class="line">    <span class="keyword">return</span> [W, b]</span><br><span class="line"></span><br><span class="line">W, b = init_params(num_inputs, num_outputs)</span><br></pre></td></tr></tbody></table></figure>
<p>网络模型</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 线性模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span>(<span class="params">X</span>):</span></span><br><span class="line">    <span class="keyword">return</span> X @ W + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># L2正则化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l2_penalty</span>(<span class="params">W</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_sum(tf.<span class="built_in">pow</span>(W, <span class="number">2</span>)) / <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># MSE损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>(<span class="params">y, y_hat</span>):</span></span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(tf.square(y - y_hat))</span><br></pre></td></tr></tbody></table></figure>
<p>训练函数</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">lambd, epochs = <span class="number">100</span>, lr = <span class="number">0.003</span></span>):</span></span><br><span class="line">    animator = d2l.Animator(xlabel=<span class="string">'epochs'</span>, ylabel=<span class="string">'loss'</span>, yscale=<span class="string">'log'</span>,</span><br><span class="line">                            xlim=[<span class="number">5</span>, epochs], legend=[<span class="string">'train'</span>, <span class="string">'test'</span>])</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="keyword">for</span> X, y <span class="keyword">in</span> train_iter:</span><br><span class="line">            <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">                <span class="comment"># 最终损失函数添加正则化项</span></span><br><span class="line">                l = loss(y, net(X)) + lambd * l2_penalty(W)</span><br><span class="line">            grads = tape.gradient(l, [W, b])</span><br><span class="line">            <span class="keyword">for</span> param, grad <span class="keyword">in</span> <span class="built_in">zip</span>([W, b], grads):</span><br><span class="line">                param.assign_sub(grad * lr)</span><br><span class="line">        <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">            animator.add(epoch +<span class="number">1</span>, (d2l.evaluate_loss(net, train_iter, loss),</span><br><span class="line">                                   (d2l.evaluate_loss(net, test_iter, loss))))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"W的L2范数是"</span>, tf.norm(W).numpy())</span><br></pre></td></tr></tbody></table></figure>
<p>train(lambd = 0)</p>
<p>模型没有泛化，光是训练误差减小，典型的过拟合。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5t4RR1.png" alt=""></p>
<p>train(lambd = 3)</p>
<p>训练和测试误差都在同步降低，且两者差距较上述过拟合之下减小了不少。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5tIZ9A.png" alt=""></p>
<p>train(lambd = 20)</p>
<p>同上，效果更好了。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5tIKnf.png" alt=""></p>
<p>train(lambd = 100)</p>
<p>虽然图形十分曲折，但总体趋势是在下降且损失更低了。</p>
<p><img src="https://z3.ax1x.com/2021/10/17/5tIJ9s.png" alt=""></p>
<h4 id="6-LASSO-回归"><a href="#6-LASSO-回归" class="headerlink" title="6. LASSO 回归"></a>6. LASSO 回归</h4><p>和岭回归类似，但正则项使用的是 L1 范数。但绝对值就意味着不可导，不好优化。</p>
<p>$loss = l(w, b) + λ||W||,\quad\quad ||W|| = \sum |W|$</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LassoRegression</span>(<span class="params">degree,alpha</span>):</span></span><br><span class="line">    pipeline = Pipeline([</span><br><span class="line">        (<span class="string">"poly"</span>,PolynomialFeatures(degree = degree)),</span><br><span class="line">        (<span class="string">"std_scaler"</span>,StandardScaler()),</span><br><span class="line">        (<span class="string">"lasso_reg"</span>,Lasso(alpha=alpha))</span><br><span class="line">    ])</span><br><span class="line">    <span class="keyword">return</span> pipeline</span><br></pre></td></tr></tbody></table></figure>
<p>alpha = 0</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UlPne.png" alt=""></p>
<p>alpha = 0.1</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UlEtI.png" alt=""></p>
<p>alpha = 1</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5Ulm1f.png" alt=""></p>
<p>alpha = 10</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UlMng.png" alt=""></p>
<p>通过对比，可以发现一个比较有意思的事情。Ridge 回归在增大 alpha 时，曲线还是<code>弯曲的</code>，但没那么陡峭，因为权重都比较小。而 LASSO 回归在增大 alpha 时，并没有那么多弯曲的地方，因此它的权重大部分都是0。</p>
<p>至于为什么会这样呢？这也和他们正则化项的式子有关。</p>
<h4 id="7-Ridge-和-LASSO-区别"><a href="#7-Ridge-和-LASSO-区别" class="headerlink" title="7. Ridge 和 LASSO 区别"></a>7. Ridge 和 LASSO 区别</h4><p><strong>Ridge 回归</strong> 的梯度是会随着离极值点越近而渐渐<code>变小</code>的，因此所有的参数是同步在更新，从图像上来看就是沿着梯度慢慢想极值点靠拢，因此不会有很多权重被设为0。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5UlxEj.png" alt=""></p>
<p><strong>LASSO 回归</strong> 的梯度是一个定值，只能由 η 来控制大小，这样就会造成部分权重会早早停在零点，这可以起到一定的特征筛选的作用，虽然也有可能将有用的特征也筛选掉。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5U3pee.png" alt=""></p>
<h4 id="8-弹性网络"><a href="#8-弹性网络" class="headerlink" title="8. 弹性网络"></a>8. 弹性网络</h4><p>顾名思义，是个弹性(折中)的网络，它结合岭回归和 LASSO 回归的思想。</p>
<p>$loss = l(w, b) + γλ||W|| + \frac{(1-γ)}{2}λ||W||^2,\quad\quad γ∈[0,1]$</p>
<p>γ 代表一种比率，取值为 0% ~ 100%，当γ = 0时，该弹性网络为岭回归；当γ = 1时，该弹性网络为 LASSO 回归。</p>
<h2 id="二、丢弃法"><a href="#二、丢弃法" class="headerlink" title="二、丢弃法"></a>二、丢弃法</h2><h4 id="1-什么是丢弃法？"><a href="#1-什么是丢弃法？" class="headerlink" title="1. 什么是丢弃法？"></a>1. 什么是丢弃法？</h4><p>丢弃法，又称 <strong>DropOut</strong>，具体做法是在每一层输出后，随机将一定量的输出置为0。那么这么做的目的是为什么呢？</p>
<p>一个好的模型需要对输入数据的扰动<strong>鲁棒</strong>。</p>
<ul>
<li>使用有噪音的数据等价于正则化。</li>
<li>丢弃法则是在层之间加入噪音，同时也降低了模型的容量。</li>
</ul>
<p><img src="https://z3.ax1x.com/2021/10/18/5admbq.png" alt=""></p>
<p>诶，那么这时有人要问了，你这随机置为0，对x的期望都变掉了。为了防止这样的情况，我们不单单是对数据置0，对另一部分的数据也要改动，保证期望不变。</p>
<p>注：p 是一个概率值，将神经元置为0的比率，$p∈[0,1]$。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5awNlQ.png" alt=""></p>
<script type="math/tex; mode=display">
Ex_i' = p * X_i * 0 + (1-p) \frac{x_i}{1-p} = x_i</script><p>左边没有 Dropout，右边有 Dropout。</p>
<p><img src="https://z3.ax1x.com/2021/10/18/5a0N4K.png" alt=""></p>
<h4 id="2-总结"><a href="#2-总结" class="headerlink" title="2.总结"></a>2.总结</h4><ul>
<li>丢弃法将一些输出项随机置0来控制模型复杂度。</li>
<li>常作用在多层感知机的隐藏层输出上。</li>
<li>丢弃概率是控制模型复杂度的超参数。</li>
</ul>
<h4 id="3-Tensorflow-实现"><a href="#3-Tensorflow-实现" class="headerlink" title="3. Tensorflow 实现"></a>3. Tensorflow 实现</h4><p>dropout层</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout_layer</span>(<span class="params">X, dropout</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="number">0</span> &lt;= dropout &lt;= <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> dropout == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> tf.zeros_like(X)</span><br><span class="line">    <span class="keyword">if</span> dropout == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># uniform 均匀分布</span></span><br><span class="line">    mask = tf.random.uniform(X.shape, minval = <span class="number">0</span>, maxval = <span class="number">1</span>) &lt; (<span class="number">1</span> - dropout)</span><br><span class="line">    <span class="comment"># 不用 X[mask] 是因为乘法运算比匹配运算快</span></span><br><span class="line">    <span class="keyword">return</span> tf.cast(mask, dtype=tf.float32) * X / (<span class="number">1.0</span> - dropout)</span><br></pre></td></tr></tbody></table></figure>
<p>测试 dropout</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试 Dropout</span></span><br><span class="line">X = tf.reshape(tf.<span class="built_in">range</span>(<span class="number">16</span>, dtype=tf.float32), [<span class="number">2</span>,<span class="number">8</span>])</span><br><span class="line"><span class="built_in">print</span>(X)</span><br><span class="line"><span class="built_in">print</span>(dropout_layer(X, <span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(dropout_layer(X, <span class="number">0.5</span>))</span><br><span class="line"><span class="built_in">print</span>(dropout_layer(X, <span class="number">1</span>))</span><br></pre></td></tr></tbody></table></figure>
<p>模型定义</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">num_outputs = <span class="number">10</span></span><br><span class="line">num_hidden1 = <span class="number">256</span></span><br><span class="line">num_hidden2 = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">dropout1 = <span class="number">0.5</span></span><br><span class="line">dropout2 = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_outputs, num_hidden1, num_hidden2</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.input_layer = keras.layers.Flatten()</span><br><span class="line">        self.hidden1 = keras.layers.Dense(num_hidden1, activation = <span class="string">"relu"</span>)</span><br><span class="line">        self.hidden2 = keras.layers.Dense(num_hidden2, activation = <span class="string">"relu"</span>)</span><br><span class="line">        self.output_layer = keras.layers.Dense(num_outputs, activation = <span class="string">"softmax"</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span></span><br><span class="line">        X = self.input_layer(inputs)</span><br><span class="line">        X = self.hidden1(X)</span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            X = dropout_layer(X, dropout1)</span><br><span class="line">        X = self.hidden2(X)</span><br><span class="line">        <span class="keyword">if</span> training:</span><br><span class="line">            X = dropout_layer(X, dropout2)</span><br><span class="line">        X = self.output_layer(X)</span><br><span class="line">        <span class="keyword">return</span> X</span><br><span class="line">    </span><br><span class="line">net = Net(num_outputs, num_hidden1, num_hidden2)</span><br></pre></td></tr></tbody></table></figure>
<p>训练</p>
<p>这里说明一下损失函数的使用情况，我之前也一直没有注意过。</p>
<ul>
<li>SparseCategoricalCrossentropy 会给 label 做一个 one-hot 编码。</li>
<li>CategoricalCrossentropy 不会给 label做 one-hot 编码。</li>
<li>from_logits = True 用于最后输出层没有经过 softmax 的情况，会给结果补做一个 softmax。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">10</span></span><br><span class="line">lr = <span class="number">0.5</span></span><br><span class="line">batch_size = <span class="number">256</span></span><br><span class="line"><span class="comment"># 若输出没有经过 softmax,需使用 keras.losses.SparseCategoricalCrossentropy(from_logits=True)</span></span><br><span class="line">loss = keras.losses.SparseCategoricalCrossentropy()</span><br><span class="line">train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)</span><br><span class="line">trainer = keras.optimizers.SGD(learning_rate = lr)</span><br><span class="line">d2l.train_ch3(net, train_iter, test_iter, loss, epochs, trainer)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://z3.ax1x.com/2021/10/19/5woMBn.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/16/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/16/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/" class="post-title-link" itemprop="url">神经网络权重的初始化</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-10-16 16:10:01 / 修改时间：19:57:58" itemprop="dateCreated datePublished" datetime="2021-10-16T16:10:01+08:00">2021-10-16</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span id="/2021/10/16/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/" class="post-meta-item leancloud_visitors" data-flag-title="神经网络权重的初始化" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/16/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/16/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E9%87%8D%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>当我们在训练一个神经网络的时候，参数的随机初始化是非常重要的，对于逻辑回归来说，可以将权重初始化为0。而对于神经网络而言，这样做将会导致梯度下降算法无法起作用。</p>
<h2 id="1-为什么使用于逻辑回归？"><a href="#1-为什么使用于逻辑回归？" class="headerlink" title="1. 为什么使用于逻辑回归？"></a>1. 为什么使用于逻辑回归？</h2><p>如下图所示，其中$X_1$ 和 $X_2$ 是特征值。</p>
<p><img src="https://z3.ax1x.com/2021/10/16/5JSZ2F.png" alt=""></p>
<p><strong>前向传播</strong>：</p>
<p>$a_1 = sigmoid(X_1 <em> W_1 + X_2 </em> W_2 + b)$</p>
<p>$loss = -ylog(a_1) - (1 - y)log(1 - a_1)$</p>
<p><strong>反向传播</strong>：</p>
<p>$da_1 = -\frac{y}{a_1} + \frac{1 - y}{1 - a_1}$</p>
<p>$dw_1 = da_1 <em> a’_1 </em> X_1 = (a_1 - y) * X_1$</p>
<p>$dw_2 = da_1 <em> a’_1 </em> X_2 = (a_1 - y) * X_2$</p>
<p>$db = da_1 <em> a’_1 </em> 1 = a_1 - y$</p>
<p><strong>参数更新</strong>：</p>
<p>$W_1 = w_1 - η * dw_1$</p>
<p>$W_2 = w_2 - η * dw_2$</p>
<p>$b = b - η * db$</p>
<p>可以看到， $W_1$ 和 $W_2$  并不影响 $dw_1$ 和 $dw_2$ 的值，而是根据 $X_1$ 和 $X_2$ 的不同而改变，且不为0，模型的权重能够得到更新。因此即使我们将 $W_1$ 和 $W_2$ 初始化为0也无所谓。参数 同理。</p>
<h2 id="2-为什么不适用于神经网络"><a href="#2-为什么不适用于神经网络" class="headerlink" title="2. 为什么不适用于神经网络?"></a>2. 为什么不适用于神经网络?</h2><p>神经网络结构图如下。</p>
<p><img src="https://z3.ax1x.com/2021/10/16/5J9qER.png" alt=""></p>
<p><strong>前向传播</strong>：</p>
<p>$a_1 = f(X_1 <em> W_{11} + X_2 </em> W_{21} + b_1)$</p>
<p>$a_2 = f(X_1 <em> W_{12} + X_2 </em> W_{22} + b_2)$</p>
<p>$a_3 = sigmoid(a_1 <em> W_{13} + a_2 </em> W_{23} + b_3)$</p>
<p>$loss = -ylog(a_3) - (1 - y)log(1 - a_3)$</p>
<p><strong>反向传播</strong>：</p>
<p>$da_3 = -\frac{y}{a_3} + \frac{1 - y}{1 - a_3}$</p>
<p>$dw_{13} = da_3 <em> a’_3 </em> a_1 = (a_3 - y) * a_1$</p>
<p>$dw_{23} = da_3 <em> a’_3 </em> a_2 = (a_3 - y) * a_2$</p>
<p>$db_{3} = da_3 <em> a’_3 </em> 1 = a_3 - y$</p>
<p>$da_1 = da_3 <em> a’_3 </em> W_{13} = (a_3 - y) * W_{13}$</p>
<p>$da_2 = da_3 <em> a’_3 </em> W_{23} = (a_3 - y) * W_{23}$</p>
<p>$dw_{12} = da_2 <em> a’_2 </em> X_1$</p>
<p>$dw_{22} = da_2 <em> a’_2 </em> X_2$</p>
<p>$db_{2} = da_2 * a’_2$</p>
<p>$dw_{11} = da_1 <em> a’_1 </em> X_1$</p>
<p>$dw_{21} = da_1 <em> a’_1 </em> X_2$</p>
<p>$db_{1} = da_1 * a’_1$</p>
<p><strong>参数更新</strong>：</p>
<p>$W_1 = w_1 - η * dw_1$</p>
<p>$W_2 = w_2 - η * dw_2$</p>
<p>$b = b - η * db$</p>
<p>根据上述的详细公式，我们分析一下3种情况：</p>
<ul>
<li>模型所有权重 W 初始化为0，所有偏置 b 初始化为0</li>
<li>模型所有权重 W 初始化为0，所有偏置 b 随机初始化</li>
<li>模型所有的权重 W 随机初始化，所有偏置 b 初始化为0</li>
</ul>
<h4 id="2-1-模型所有权重-W-初始化为0，所有偏置-b-初始化为0"><a href="#2-1-模型所有权重-W-初始化为0，所有偏置-b-初始化为0" class="headerlink" title="2.1 模型所有权重 W 初始化为0，所有偏置 b 初始化为0"></a>2.1 模型所有权重 W 初始化为0，所有偏置 b 初始化为0</h4><p>在此情况下， 第一个 batch 的前向传播过程时，$a_1 = f(0), a_2 = f(0), a_3 = sigmoid(0)$。在反向传播进行参数更新的时候，会发现 $a_1 = a_2 = f(0) \ \  =&gt;\ \  dw_{13} = dw_{23}$，$W_{13} = W_{23} = 0 \ \  =&gt; \ \ da_1 = da_2 = 0$。也就是说，在第一个 batch 中，只有 $W_{13}$ 和 ${W_{23}}$ 进行了更新并且<code>相等</code>，而其它参数均没有更新。</p>
<p>而当第二个 batch 传给神经网络时，$W_{13} = W_{23} \neq 0 \ \  =&gt;\ \  da_1 = da_2 \ \ =&gt; dw_{21} = dw_{22},\ dw_{11} = dw_{12}$。</p>
<p>以此类推，无论训练多少次，无论隐藏层神经元有多少个，由于权重的<code>对称性</code>，隐藏层神经单元的输出始终不变(权重相等)。我们希望不同的神经元能够有不同的输出，这样的神经网络才有意义。</p>
<p><strong>总结：将权重 W 初始化为0，会导致同一隐藏层的所有神经元输出都一致。对于后期不同的 batch，每一隐藏层的权重都能得到更新，但是每一隐藏层神经元的权重都是一致的，多个隐藏神经元的作用就如同1个神经元。</strong></p>
<h4 id="2-2-模型所有权重-W-初始化为0，所有偏置-b-随机初始化"><a href="#2-2-模型所有权重-W-初始化为0，所有偏置-b-随机初始化" class="headerlink" title="2.2 模型所有权重 W 初始化为0，所有偏置 b 随机初始化"></a>2.2 模型所有权重 W 初始化为0，所有偏置 b 随机初始化</h4><p>在此情况下，第一个 batch 的前向传播过程时，$a_1 = f(b_1), a_2 = f(b_2), a_3 = sigmoid(b_3)$，在反向传播过程时，$da_1 = da_2 = 0 \ \ =&gt; \ \ dw_{11} = dw_{12} = dw_{21} = dw_{22} = 0$，因此第一个 batch 中只有 $W_{13}, W_{23}$ 和 $B_{3}$ 能得到更新。</p>
<p>同理，在第二个 batch 反向传播的过程中，由于 $W_{13}$ 和 $W_{23}$ 不为0，因此所有的参数都能得到更新。<strong>这种方式存在更新较慢、梯度消失、梯度爆炸等问题，在实践中，通常不会选择该方法。</strong></p>
<h4 id="2-3-模型所有的权重-W-随机初始化，所有偏置-b-初始化为0"><a href="#2-3-模型所有的权重-W-随机初始化，所有偏置-b-初始化为0" class="headerlink" title="2.3 模型所有的权重 W 随机初始化，所有偏置 b 初始化为0"></a>2.3 模型所有的权重 W 随机初始化，所有偏置 b 初始化为0</h4><p>在此情况下，第一个 batch 的前向传播过程时，由于 $W_{13}$ 和 $W_{23}$ 不为0，因此所有的参数可以直接得到更新。</p>
<h2 id="结论：在训练神经网络的时候，权重初始化要谨慎，不能初始化为0！"><a href="#结论：在训练神经网络的时候，权重初始化要谨慎，不能初始化为0！" class="headerlink" title="结论：在训练神经网络的时候，权重初始化要谨慎，不能初始化为0！"></a><strong>结论：在训练神经网络的时候，权重初始化要谨慎，不能初始化为0！</strong></h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/14/%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/14/%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/" class="post-title-link" itemprop="url">注解和反射</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-10-14 08:52:09 / 修改时间：13:32:45" itemprop="dateCreated datePublished" datetime="2021-10-14T08:52:09+08:00">2021-10-14</time>
            </span>

          
            <span id="/2021/10/14/%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/" class="post-meta-item leancloud_visitors" data-flag-title="注解和反射" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/14/%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/14/%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1、注解"><a href="#1、注解" class="headerlink" title="1、注解"></a>1、注解</h2><h4 id="1-1、-内置注解"><a href="#1-1、-内置注解" class="headerlink" title="1.1、 内置注解"></a>1.1、 内置注解</h4><ul>
<li><p>@Deprecated</p>
<p>被注解的元素是不鼓励使用的程序元素，通常是因为它是<code>危险</code>的，或者因为存在更好的替代方法。</p>
</li>
<li><p>@Override</p>
<p>表示重写父类方法。</p>
</li>
<li><p>@SuppressWarning</p>
<p>抑制警告。</p>
</li>
<li><p>@FunctionaInterface</p>
<p>指定接口必须为函数式接口。</p>
</li>
</ul>
<h4 id="1-2、元注解"><a href="#1-2、元注解" class="headerlink" title="1.2、元注解"></a>1.2、元注解</h4><p>元注解的作用就是负责<code>注解</code>其它注解。</p>
<ul>
<li><p>@Target</p>
<p>用于描述注解的使用范围。</p>
</li>
<li><p>@Retention</p>
<p>表示需要在什么级别保存该注释信息，用于描述注解的生命周期。</p>
<ul>
<li>SOURCE &lt; CLASS &lt; RUNTIME</li>
</ul>
</li>
<li><p>@Document</p>
<p>说明该注解将被包含在 javadoc 中。</p>
</li>
<li><p>@Inherited</p>
<p>说明子类可以<code>继承</code>父类中的该注释。</p>
</li>
</ul>
<h2 id="1-3、自定义注解"><a href="#1-3、自定义注解" class="headerlink" title="1.3、自定义注解"></a>1.3、自定义注解</h2><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.lang.annotation.*;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Target(ElementType.FIELD)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Inherited</span></span><br><span class="line"><span class="meta">@interface</span> MyAnnotation1{</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">age</span><span class="params">()</span></span>;</span><br><span class="line">    String[] hobby() <span class="keyword">default</span> {<span class="string">"dance"</span>, <span class="string">"sing"</span>};</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="meta">@Target(ElementType.FIELD)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@interface</span> MyAnnotation2{</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span></span>;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>注解中的参数一定要加<code>()</code>！</p>
<p>当注解只有一个参数时，参数名可以定义为 <code>value</code>，在调用的时候直接赋值就行。</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyAnnotationTest</span> </span>{</span><br><span class="line">    <span class="meta">@MyAnnotation1(age = 12)</span></span><br><span class="line">    <span class="meta">@MyAnnotation2("value")</span></span><br><span class="line">    String name;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="2、反射"><a href="#2、反射" class="headerlink" title="2、反射"></a>2、反射</h2><p>Java 反射就是在<code>运行</code>状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意方法和属性，并且能改变它的属性。</p>
<h4 id="2-1、获取-Class-类的实例"><a href="#2-1、获取-Class-类的实例" class="headerlink" title="2.1、获取 Class 类的实例"></a>2.1、获取 Class 类的实例</h4><ul>
<li><p>通过类的 class 属性获取，安全可靠，性能最高。</p>
<p><code>Class clz = Person.class;</code></p>
</li>
<li><p>调用实例的 getClass() 方法。</p>
<p><code>Class clz = person.getClass();</code></p>
</li>
<li><p>通过 Class.forName() 获取。</p>
<p><code>Class clz = Class.forName("com.yqx.Person");</code></p>
</li>
</ul>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test1</span><span class="params">()</span> <span class="keyword">throws</span> ClassNotFoundException </span>{</span><br><span class="line">    Class clz1 = Person.class;</span><br><span class="line">    Class clz2 = <span class="keyword">new</span> Person().getClass();</span><br><span class="line">    Class clz3 = Class.forName(<span class="string">"Person"</span>);</span><br><span class="line">    System.out.println(clz1 == clz2);	<span class="comment">// true</span></span><br><span class="line">    System.out.println(clz2 == clz3);	<span class="comment">// true</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h4 id="2-2、拥有-Class-对象的类型"><a href="#2-2、拥有-Class-对象的类型" class="headerlink" title="2.2、拥有 Class 对象的类型"></a>2.2、拥有 Class 对象的类型</h4><ul>
<li>class：外部类，成员，局部内部类，匿名内部类。</li>
<li>interface：接口</li>
<li>[]：数组</li>
<li>enum：枚举</li>
<li>annotation：注解 @interface</li>
<li>primitive type：基本数据类型</li>
<li>void</li>
</ul>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test2</span><span class="params">()</span></span>{</span><br><span class="line">    Class clz1 = Object.class;</span><br><span class="line">    Class clz2 = Comparable.class;</span><br><span class="line">    Class clz3 = String[].class;</span><br><span class="line">    Class clz4 = String[][].class;</span><br><span class="line">    Class clz5 = Override.class;</span><br><span class="line">    Class clz6 = ElementType.class;</span><br><span class="line">    Class clz7 = Integer.class;</span><br><span class="line">    Class clz8 = <span class="keyword">void</span>.class;</span><br><span class="line">    Class clz9 = Class.class;</span><br><span class="line"></span><br><span class="line">    System.out.println(clz1);</span><br><span class="line">    System.out.println(clz2);</span><br><span class="line">    System.out.println(clz3);</span><br><span class="line">    System.out.println(clz4);</span><br><span class="line">    System.out.println(clz5);</span><br><span class="line">    System.out.println(clz6);</span><br><span class="line">    System.out.println(clz7);</span><br><span class="line">    System.out.println(clz8);</span><br><span class="line">    System.out.println(clz9);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10</span>];</span><br><span class="line">    <span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">100</span>];</span><br><span class="line">    System.out.println(a.getClass() == b.getClass());</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>打印输出 (数组即使长度不同，其 Class 类也都是相同的)</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span></span></span><br><span class="line"><span class="class"><span class="title">interface</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Comparable</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> [<span class="title">Ljava</span>.<span class="title">lang</span>.<span class="title">String</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span> [[<span class="title">Ljava</span>.<span class="title">lang</span>.<span class="title">String</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Override</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">annotation</span>.<span class="title">ElementType</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Integer</span></span></span><br><span class="line"><span class="class"><span class="title">void</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Class</span></span></span><br><span class="line"><span class="class"><span class="title">true</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">Process</span> <span class="title">finished</span> <span class="title">with</span> <span class="title">exit</span> <span class="title">code</span> 0</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="2-3、类的加载"><a href="#2-3、类的加载" class="headerlink" title="2.3、类的加载"></a>2.3、类的加载</h4><p><img src="https://z3.ax1x.com/2021/10/14/5QnMng.png" alt=""></p>
<p><img src="https://z3.ax1x.com/2021/10/14/5QnIUA.png" alt=""></p>
<h4 id="2-4、获取类的属性及方法"><a href="#2-4、获取类的属性及方法" class="headerlink" title="2.4、获取类的属性及方法"></a>2.4、获取类的属性及方法</h4><p>反射机制允许程序在运行时取得任何一个已知名称的 class 的内部信息，包括包括其modifiers (修饰符)，fields (属性)，methods (方法)等，并可于运行时改变 fields 内容或调用 methods。</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test3</span><span class="params">()</span> <span class="keyword">throws</span> ClassNotFoundException, IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException, NoSuchFieldException </span>{</span><br><span class="line">        <span class="comment">// 获取 Class 对象</span></span><br><span class="line">        Class c1 = Class.forName(<span class="string">"Person"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建对象(无参)</span></span><br><span class="line">        Person person1 = (Person) c1.newInstance();</span><br><span class="line">        System.out.println(person1);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 通过构造器创建对象</span></span><br><span class="line">        Constructor constructor = c1.getDeclaredConstructor(String.class, <span class="keyword">int</span>.class);</span><br><span class="line">        Person person2 = (Person) constructor.newInstance(<span class="string">"yqx"</span>, <span class="number">20</span>);</span><br><span class="line">        System.out.println(person2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 反射调用方法</span></span><br><span class="line">        Method method1 = c1.getDeclaredMethod(<span class="string">"getName"</span>);</span><br><span class="line">        Method method2 = c1.getDeclaredMethod(<span class="string">"setName"</span>, String.class);</span><br><span class="line">        String name1 = (String) method1.invoke(person1);</span><br><span class="line">        method2.invoke(person1, <span class="string">"deflory"</span>);</span><br><span class="line">        String name2 = (String) method1.invoke(person1);</span><br><span class="line">        System.out.println(<span class="string">"Before: "</span> + name1);</span><br><span class="line">        System.out.println(<span class="string">"After: "</span> + name2);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 反射操作属性</span></span><br><span class="line">        Field field = c1.getDeclaredField(<span class="string">"age"</span>);</span><br><span class="line">        field.setAccessible(<span class="keyword">true</span>);  <span class="comment">// 设置可访问的</span></span><br><span class="line">        field.set(person1, <span class="number">18</span>);</span><br><span class="line">        System.out.println(person1.getAge());</span><br><span class="line">    }</span><br></pre></td></tr></tbody></table></figure>
<p>打印内容</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Person{name=<span class="string">'null'</span>, age=<span class="number">0</span>}</span><br><span class="line">Person{name=<span class="string">'yqx'</span>, age=<span class="number">20</span>}</span><br><span class="line">Before: <span class="keyword">null</span></span><br><span class="line">After: deflory</span><br><span class="line"><span class="number">18</span></span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="2-5、性能测试"><a href="#2-5、性能测试" class="headerlink" title="2.5、性能测试"></a>2.5、性能测试</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test4</span><span class="params">()</span> <span class="keyword">throws</span> NoSuchMethodException, InvocationTargetException, IllegalAccessException </span>{</span><br><span class="line">    <span class="comment">// 普通方法</span></span><br><span class="line">    Person person = <span class="keyword">new</span> Person();</span><br><span class="line">    <span class="keyword">long</span> start = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1e9</span>;i++){</span><br><span class="line">        person.getAge();</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">long</span> end = System.currentTimeMillis();</span><br><span class="line">    System.out.println(<span class="string">"普通方法用时："</span> + (end - start) + <span class="string">"ms"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 反射(检测开启)</span></span><br><span class="line">    Method method = Person.class.getDeclaredMethod(<span class="string">"getAge"</span>);</span><br><span class="line">    start = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1e9</span>;i++){</span><br><span class="line">        method.invoke(person);</span><br><span class="line">    }</span><br><span class="line">    end = System.currentTimeMillis();</span><br><span class="line">    System.out.println(<span class="string">"反射(检测开启)用时："</span> + (end - start) + <span class="string">"ms"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 反射(检测关闭)</span></span><br><span class="line">    method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">    start = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1e9</span>;i++){</span><br><span class="line">        method.invoke(person);</span><br><span class="line">    }</span><br><span class="line">    end = System.currentTimeMillis();</span><br><span class="line">    System.out.println(<span class="string">"反射(检测关闭)用时："</span> + (end - start) + <span class="string">"ms"</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>打印内容</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">普通方法用时：1379ms</span><br><span class="line">反射(检测开启)用时：1863ms</span><br><span class="line">反射(检测关闭)用时：1591ms</span><br><span class="line"></span><br><span class="line">Process finished with exit code <span class="number">0</span></span><br></pre></td></tr></tbody></table></figure>
<h4 id="2-6、反射操作泛型"><a href="#2-6、反射操作泛型" class="headerlink" title="2.6、反射操作泛型"></a>2.6、反射操作泛型</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test5</span><span class="params">()</span> <span class="keyword">throws</span> NoSuchMethodException </span>{</span><br><span class="line">    Method test01 = Person.class.getDeclaredMethod(<span class="string">"test01"</span>, Map.class, List.class);</span><br><span class="line">    Method test02 = Person.class.getDeclaredMethod(<span class="string">"test02"</span>);</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"test01(参数泛型)"</span>);</span><br><span class="line">    Type[] genericParameterTypes = test01.getGenericParameterTypes();</span><br><span class="line">    <span class="keyword">for</span>(Type genericParameterType : genericParameterTypes){</span><br><span class="line">        System.out.println(genericParameterType);</span><br><span class="line">        <span class="keyword">if</span> (genericParameterType <span class="keyword">instanceof</span> ParameterizedType){</span><br><span class="line">            Type[] actualTypeArguments = ((ParameterizedType) genericParameterType).getActualTypeArguments();</span><br><span class="line">            <span class="keyword">for</span>(Type actualTypeArgument : actualTypeArguments){</span><br><span class="line">                System.out.println(actualTypeArgument);</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"\ntest02(返回值泛型)"</span>);</span><br><span class="line">    Type getGenericReturnType = test02.getGenericReturnType();</span><br><span class="line">    System.out.println(getGenericReturnType);</span><br><span class="line">    <span class="keyword">if</span> (getGenericReturnType <span class="keyword">instanceof</span> ParameterizedType){</span><br><span class="line">        Type[] actualTypeArguments = ((ParameterizedType) getGenericReturnType).getActualTypeArguments();</span><br><span class="line">        <span class="keyword">for</span>(Type actualTypeArgument : actualTypeArguments){</span><br><span class="line">            System.out.println(actualTypeArgument);</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>打印内容</p>
<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">test01(参数泛型)</span><br><span class="line">java.util.Map&lt;java.lang.String, java.lang.Integer&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">String</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Integer</span></span></span><br><span class="line"><span class="class"><span class="title">java</span>.<span class="title">util</span>.<span class="title">List</span>&lt;<span class="title">java</span>.<span class="title">lang</span>.<span class="title">Character</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Character</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">test02</span>(返回值泛型)</span></span><br><span class="line"><span class="class"><span class="title">java</span>.<span class="title">util</span>.<span class="title">Map</span>&lt;<span class="title">java</span>.<span class="title">lang</span>.<span class="title">String</span>, <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Integer</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">String</span></span></span><br><span class="line"><span class="class"><span class="title">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Integer</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">Process</span> <span class="title">finished</span> <span class="title">with</span> <span class="title">exit</span> <span class="title">code</span> </span></span><br></pre></td></tr></tbody></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/08/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/08/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83/" class="post-title-link" itemprop="url">模型的训练</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-08 23:22:35" itemprop="dateCreated datePublished" datetime="2021-10-08T23:22:35+08:00">2021-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-20 22:38:37" itemprop="dateModified" datetime="2021-10-20T22:38:37+08:00">2021-10-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span id="/2021/10/08/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83/" class="post-meta-item leancloud_visitors" data-flag-title="模型的训练" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/08/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/08/%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1、网格搜索"><a href="#1、网格搜索" class="headerlink" title="1、网格搜索"></a>1、网格搜索</h2><h4 id="1-1、什么是网格搜索？"><a href="#1-1、什么是网格搜索？" class="headerlink" title="1.1、什么是网格搜索？"></a>1.1、什么是网格搜索？</h4><p>在 <a href="/2021/09/28/过拟合和欠拟合/">过拟合和欠拟合</a> 中，我们是手动调整超参数 <code>degree</code> ，经由人工一一比对来获取最好的值，效率比较低下。因此我们引入网格搜索这个概念，不要被这个看起来很高大上的名词吓唬住了，其实逻辑十分简单，具体请看下述代码。</p>
<p>使用 sklearn 中自带的波士顿房产数据作为我们的测试数据。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">boston = datasets.load_boston()</span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y)</span><br></pre></td></tr></tbody></table></figure>
<p>这里我们要网格搜索的参数即为 p，neighbor， weight。</p>
<p>可以看到所谓 <code>网格搜索</code> 就是使用 for-loop 像网格一样将你预设的可能的值都遍历一遍，依次寻求 score 最高的超参数组合。</p>
<figure class="highlight markdown"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">KNN中的超参数：</span><br><span class="line"><span class="bullet">  -</span> weights：含有 <span class="code">`uniform`</span> 和 <span class="code">`distance`</span> 两种模式</span><br><span class="line"><span class="code">             uniform 是正常的模式</span></span><br><span class="line"><span class="code">             distance 给 k 个相邻的点按照距离远近都赋予一个权重，离预测样本点距离远的权重就低一些，距离近的权重就高一些，</span></span><br><span class="line"><span class="code">             </span></span><br><span class="line"><span class="code">  - p：闵可夫斯基距离参数</span></span><br><span class="line"><span class="code">       p = 1 时，等价于曼哈顿距离</span></span><br><span class="line"><span class="code">       p = 2 时，等价于欧拉距离</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">weights = [<span class="string">"uniform"</span>, <span class="string">"distance"</span>]</span><br><span class="line">best_score = -<span class="number">1</span></span><br><span class="line">best_p = <span class="number">0</span></span><br><span class="line">best_neighbor = <span class="number">0</span></span><br><span class="line">best_weight = <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> weight <span class="keyword">in</span> weights:</span><br><span class="line">    <span class="keyword">for</span> neighbor <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>):</span><br><span class="line">            reg = KNeighborsRegressor(n_neighbors=neighbor,</span><br><span class="line">                                      weights = weight,</span><br><span class="line">                                      p = p,</span><br><span class="line">                                      n_jobs = -<span class="number">1</span>)</span><br><span class="line">            reg.fit(X_train, y_train)</span><br><span class="line">            score = reg.score(X_test, y_test)</span><br><span class="line">            <span class="keyword">if</span> score &gt; best_score:</span><br><span class="line">                best_score = score</span><br><span class="line">                best_neighbor = neighbor</span><br><span class="line">                best_p = p</span><br><span class="line">                best_weight = weight</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">"best_weight ="</span>, best_weight)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"best_p ="</span>, best_p)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"best_neighbor ="</span>, best_neighbor)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"best_score ="</span>, best_score)</span><br></pre></td></tr></tbody></table></figure>
<p>输出结果如下。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">best_weight = distance</span><br><span class="line">best_p = <span class="number">1</span></span><br><span class="line">best_neighbor = <span class="number">3</span></span><br><span class="line">best_score = <span class="number">0.7420720968121362</span></span><br></pre></td></tr></tbody></table></figure>
<p>注：KNeighborsRegressor 和 KNeighborsClassifier 思想相同。</p>
<p>KNeighborsClassifier 是找到附近 <code>k</code> 个数据，找到最多那个类别作为预测的<code>类别</code>，用于解决分类问题。</p>
<p>而 KNeighborsRegressor 是找到附近 <code>k</code> 个数据，然后取平均值作为预测的<code>数值</code>，用于解决回归问题。</p>
<p><br></p>
<h4 id="1-2、scikit-中的实现"><a href="#1-2、scikit-中的实现" class="headerlink" title="1.2、scikit 中的实现"></a>1.2、scikit 中的实现</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">params = {</span><br><span class="line">    <span class="string">"weights"</span> : [<span class="string">"uniform"</span>, <span class="string">"distance"</span>],</span><br><span class="line">    <span class="string">"p"</span> : [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)],</span><br><span class="line">    <span class="string">"n_neighbors"</span> : [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">knn_reg = KNeighborsRegressor()</span><br><span class="line">grid_search=GridSearchCV(knn_reg, params)</span><br><span class="line">%time grid_search.fit(X_train,y_train)</span><br></pre></td></tr></tbody></table></figure>
<p>GridSearchCV 使用交叉验证来训练数据，即 train-validation-test。因此best_score_可能会比较低。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grid_search.best_params_ = {<span class="string">'n_neighbors'</span>: <span class="number">5</span>, <span class="string">'p'</span>: <span class="number">1</span>, <span class="string">'weights'</span>: <span class="string">'distance'</span>}</span><br><span class="line">grid_search.best_score_ = <span class="number">0.6091159004372775</span></span><br><span class="line">grid_search.best_estimator_.score(X_test, y_test) = <span class="number">0.7276418519232821</span></span><br></pre></td></tr></tbody></table></figure>
<p><br></p>
<h2 id="2、交叉验证"><a href="#2、交叉验证" class="headerlink" title="2、交叉验证"></a>2、交叉验证</h2><p>在之前模型的训练中，我们都是以测试数据集的 score 来衡量模型的好坏，换言之就是根据 <code>test_score</code> 来调整超参数，并从所有的模型中挑出 <code>test_score</code> 最高的作为我们的预测模型。但这样也会暴露出一个问题，在模型训练期间，我们的模型就已经<code>见过</code>了测试数据集，因此可能会<code>过拟合</code>测试数据集！</p>
<p>这样肯定是不对的，要模拟真正的生产环境，那么测试数据集就不能参与到模型的训练当中。我们只需要再引入一个验证数据集来<code>代替</code>之前测试数据集的作用就行了。</p>
<p><img src="https://z3.ax1x.com/2021/10/10/5kvEY4.png" alt=""></p>
<p>但其实这样也会有<code>过拟合</code>验证数据集的问题，因此就有了<code>交叉验证</code>。具体则是将训练数据集分成 K 份，从这 K 份当中选择一份作为验证数据集，其余 K-1 份作为训练数据集。一共有 $C^1_K = K$ 种分法，因此我们可以得到 K 个模型，因此这也被称为 <code>K-folds Cross  Validation</code>（K折交叉验证），最后取他们在验证数据集上的均值作为判断模型好坏的依据。</p>
<p>这里提一句，在 scikit-learn 的网格搜索中，默认使用的是 cv = 5 的交叉验证，也就是五折交叉验证。</p>
<p><img src="https://z3.ax1x.com/2021/10/10/5kvFTU.png" alt=""></p>
<p>当交叉验证的 K = n_samples 时，会产生 n_samples 个模型，这时训练出来的模型完全不受随机的影响，将最接近模型真正的性能指标，代价就是训练时间会扩大 n_samples 倍，这就是 <code>LOO-CV</code>（Leave One Out Cross Validtion），也就是留一法。</p>
<h4 id="2-2、代码实现"><a href="#2-2、代码实现" class="headerlink" title="2.2、代码实现"></a>2.2、代码实现</h4><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将第i份作为验证集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_k_fold_data</span>(<span class="params">k, i, X, y</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> k &gt; <span class="number">1</span></span><br><span class="line">    fold_size = X.shape[<span class="number">0</span>] // k</span><br><span class="line">    X_train, y_train = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        idx = <span class="built_in">slice</span>(j * fold_size, (j+<span class="number">1</span>) * fold_size)</span><br><span class="line">        X_part, y_part = X[idx, :], y[idx]</span><br><span class="line">        <span class="comment"># 第i份即为验证集</span></span><br><span class="line">        <span class="keyword">if</span> j == i:</span><br><span class="line">            X_valid, y_valid = X_part, y_part</span><br><span class="line">        <span class="comment"># 除第i份以外的第一份作为train的开头</span></span><br><span class="line">        <span class="keyword">elif</span> X_train <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            X_train, y_train = X_part, y_part</span><br><span class="line">        <span class="comment"># 其余拼接到后面</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            X_train = tf.concat([X_train, X_part], <span class="number">0</span>)</span><br><span class="line">            y_train = tf.concat([y_train, y_part], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> X_train, y_train, X_valid, y_valid</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉验证</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">k_fold</span>(<span class="params">k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size</span>):</span></span><br><span class="line">    train_loss_sum, valid_loss_sum = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        data = get_k_fold_data(k, i, X_train, y_train)</span><br><span class="line">        net = get_net()</span><br><span class="line">        train_loss, valid_loss = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)</span><br><span class="line">        train_loss_sum += train_loss[-<span class="number">1</span>]</span><br><span class="line">        valid_loss_sum += valid_loss[-<span class="number">1</span>]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f'fold <span class="subst">{i + <span class="number">1</span>}</span>, train log rmse <span class="subst">{<span class="built_in">float</span>(train_loss[-<span class="number">1</span>]):f}</span>, '</span></span><br><span class="line">              <span class="string">f'valid log rmse <span class="subst">{<span class="built_in">float</span>(valid_loss[-<span class="number">1</span>]):f}</span>'</span>)</span><br><span class="line">    <span class="keyword">return</span> train_loss_sum / k, valid_loss_sum / k</span><br></pre></td></tr></tbody></table></figure>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/10/08/Spring/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/10/08/Spring/" class="post-title-link" itemprop="url">Spring</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-10-08 16:08:33" itemprop="dateCreated datePublished" datetime="2021-10-08T16:08:33+08:00">2021-10-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-11-12 17:58:47" itemprop="dateModified" datetime="2021-11-12T17:58:47+08:00">2021-11-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/SSM/" itemprop="url" rel="index"><span itemprop="name">SSM</span></a>
                </span>
            </span>

          
            <span id="/2021/10/08/Spring/" class="post-meta-item leancloud_visitors" data-flag-title="Spring" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/10/08/Spring/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/10/08/Spring/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1、-Spring"><a href="#1、-Spring" class="headerlink" title="1、 Spring"></a>1、 Spring</h2><h4 id="1-1、-简介"><a href="#1-1、-简介" class="headerlink" title="1.1、 简介"></a>1.1、 简介</h4><ul>
<li>Spring：春天 ——&gt; 给软件行业带来了春天！</li>
<li>2002年，首次推出了 <code>Spring</code> 框架的雏形：interface21 框架！</li>
<li><code>Spring</code> 框架即以 interface21 框架为基础，经过重新设计，并不断丰富其内涵，于2004年3月24日，发布了1.0正式版。</li>
<li><strong>Rod Johnson</strong>，Spring Framework 创始人，著名作家，还是悉尼大学的音乐学博士。</li>
<li>spring理念：使现有的技术更加容易使用，本身是个大杂烩，整合了现有的技术框架！</li>
</ul>
<ul>
<li>SSH：Struts2 + Spring + Hibernate</li>
<li>SSM：SpringMvc + Spring + Mybatis</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/10/08/Spring/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/28/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/28/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/" class="post-title-link" itemprop="url">过拟合和欠拟合</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-28 15:51:43" itemprop="dateCreated datePublished" datetime="2021-09-28T15:51:43+08:00">2021-09-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-19 19:48:13" itemprop="dateModified" datetime="2021-10-19T19:48:13+08:00">2021-10-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span id="/2021/09/28/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/" class="post-meta-item leancloud_visitors" data-flag-title="过拟合和欠拟合" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/09/28/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/09/28/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>继之前的<a href="/2021/09/27/多项式回归/">多项式回归</a>，如果 <code>degree</code> 设置过大或者过小会出现什么样的问题呢？</p>
<p>在此之前，先来说明一下 <a href="/2021/09/14/数据归一化/">归一化</a> 的必要性。多项式回归采用了特征组合的方式，当 <code>degree</code> 为100时，最高次就是100次，而最低次只是常数级，各个维度数值之间的跨度非常大，这就导致 <code>eta</code> 必须设置得非常小，否则稍大一点，就会无法拟合，变成 <code>nan</code> 。</p>
<p>当 degree 为10时， eta就必须设置成$10^{-19}$，很不利于我们训练模型，所以在数据与距离阶段除了要多项式化还得归一化！</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4feNrT.png" alt=""></p>
<p>根据上述要求，改进了一下多项式回归的类。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PolynomialRegression</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, degree</span>):</span></span><br><span class="line">        self.degree = degree</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y, eta = <span class="number">0.01</span>, n_iters = <span class="number">1e4</span>, epsilon = <span class="number">1e-6</span></span>):</span></span><br><span class="line">        self.X = self._getPolynomialFeatures(X, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), self.degree)</span><br><span class="line">        self.X = self.standardization(self.X)</span><br><span class="line">        </span><br><span class="line">        initial_theta = np.zeros([self.X.shape[<span class="number">1</span>]])</span><br><span class="line">        theta = self._gradient_descent(self.X, y, initial_theta, eta, n_iters, epsilon)</span><br><span class="line">        self.theta = theta</span><br><span class="line">        self.coefficient = theta[<span class="number">1</span>:]</span><br><span class="line">        self.intercept = theta[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 归一化</span></span><br><span class="line">    <span class="comment"># 第一列全为1方差为0要单独处理，改成第一列全为0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">standardization</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> np.hstack([np.zeros([<span class="built_in">len</span>(X), <span class="number">1</span>]), (X[:, <span class="number">1</span>:] - np.mean(X[:, <span class="number">1</span>:], axis = <span class="number">0</span>)) / np.std(X[:, <span class="number">1</span>:], axis = <span class="number">0</span>)])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 多项式化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_getPolynomialFeatures</span>(<span class="params">self, X, start, col_val, degree</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">X, result, start, col_val, degree</span>):</span></span><br><span class="line">            result.append(col_val)</span><br><span class="line">            <span class="keyword">if</span>(degree == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, X.shape[<span class="number">1</span>]):</span><br><span class="line">                dfs(X, result, start, col_val * X[:, i].reshape([-<span class="number">1</span>, <span class="number">1</span>]), degree - <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        dfs(X, result, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), degree)</span><br><span class="line">        <span class="keyword">return</span> np.squeeze(np.array(result), -<span class="number">1</span>).T</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测也要多项式化和归一化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        X_b = self._getPolynomialFeatures(X, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), self.degree)</span><br><span class="line">        X_b = self.standardization(X_b)</span><br><span class="line">        y_pred = X_b.dot(self.theta)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># MSE</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        y_pred = self.predict(X)</span><br><span class="line">        <span class="keyword">return</span> np.mean((y - y_pred) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_gradient_descent</span>(<span class="params">self, X_b, y, theta, eta, n_iters, epsilon</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">J</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">            <span class="keyword">return</span> np.mean((X_b.dot(theta) - y) ** <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">DJ</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">            <span class="keyword">return</span> X_b.T.dot((X_b.dot(theta) - y)) * <span class="number">2</span> / <span class="built_in">len</span>(y);</span><br><span class="line">        </span><br><span class="line">        i_iter = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span> i_iter &lt; n_iters:</span><br><span class="line">            gradient = DJ(X_b, y, theta)</span><br><span class="line">            last_theta = theta</span><br><span class="line">            theta = theta - eta * gradient</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(J(X_b, y, theta) - J(X_b, y, last_theta)) &lt; epsilon:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            i_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> theta</span><br></pre></td></tr></tbody></table></figure>
<p>当然直接使用 sklearn 中的 <code>Pipeline</code> 可以更加简便的实现这一切。</p>
<p><code>Pipeline</code> 具体运作机制就是逐行运行，上一行的输出就是下一行的输入，因此我们先进行多项式化，再归一化，最后放入线性回归中训练模型。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PolynomialRegression</span>(<span class="params">X,y,degree</span>):</span></span><br><span class="line">    pipeline = Pipeline([</span><br><span class="line">        (<span class="string">"poly"</span>,PolynomialFeatures(degree = degree)),</span><br><span class="line">        (<span class="string">"std_scaler"</span>,StandardScaler()),</span><br><span class="line">        (<span class="string">"lin_reg"</span>,LinearRegression())</span><br><span class="line">    ])</span><br><span class="line">    pipeline.fit(X,y)</span><br><span class="line">    <span class="keyword">return</span> pipeline.predict(X)</span><br></pre></td></tr></tbody></table></figure>
<p><br></p>
<h2 id="数据拟合"><a href="#数据拟合" class="headerlink" title="数据拟合"></a>数据拟合</h2><p>先写一个绘制拟合曲线的函数便于我们观测结果。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_matching_curve</span>(<span class="params">X, y, degree, eta = <span class="number">1e-6</span>, n_iters = <span class="number">1e5</span></span>):</span></span><br><span class="line">    poly_reg = PolynomialRegression(degree)</span><br><span class="line">    poly_reg.fit(X, y, eta, n_iters)</span><br><span class="line">    theta = poly_reg.theta</span><br><span class="line">    pred_y = poly_reg.X.dot(theta)</span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], y)</span><br><span class="line">    plt.plot(X[:, <span class="number">0</span>], pred_y, color = <span class="string">"r"</span>)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> poly_reg</span><br></pre></td></tr></tbody></table></figure>
<p>当 degree 为0时，也就是最高次为0次，拟合曲线成一条直线，这就是欠拟合。</p>
<p>毕竟函数只有一个常数嘛，合理。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_matching_curve(x.reshape([-<span class="number">1</span>, <span class="number">1</span>]), y, <span class="number">0</span>)</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://z3.ax1x.com/2021/09/28/4fEsRP.png" alt=""></p>
<p>再来看看 degree 分别为1，2的情况，是不是越来越接近我们的拟合曲线了。</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4fVdyT.png" alt=""></p>
<p><img src="https://z3.ax1x.com/2021/09/28/4fV50e.png" alt=""></p>
<p>当 degree 为3时，曲线终于拟合了我们的数据。</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4fZQ91.png" alt=""></p>
<p>那我们再看看 degree 为10，50，100，200的情况。</p>
<p>很容易可以观察出，曲线变得越来越复杂，也越来越能拟合我们的训练数据，这是因为随着 degree 的增大，参数数量的增长使得我们的模型可以将训练的数据给<code>记住</code>，但这真的是我们想要的吗？</p>
<p>不，我们想要的是<code>泛化</code>能力，是在测试数据乃至之后模型上线后的真实数据上也能有非常好的预测能力。</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4f1qaV.png" alt=""></p>
<p><img src="https://z3.ax1x.com/2021/09/28/4f39q1.png" alt=""></p>
<p><img src="https://z3.ax1x.com/2021/09/28/4f3ia6.png" alt=""></p>
<p>之前也说过了，多项式化是阶乘式地增长，一旦 <code>degree</code> 过大，直接就会导致栈溢出。</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4f3nsA.png" alt=""></p>
<p><br></p>
<h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><p>通过观察学习曲线，也可以帮助我们判断出模型是否有过拟合或欠拟合的情况。它是绘制模型在训练集和测试集上的性能函数。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, PolynomialFeatures</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_poly_reg</span>(<span class="params">degree</span>):</span></span><br><span class="line">    <span class="keyword">return</span> Pipeline([</span><br><span class="line">        (<span class="string">"poly"</span>, PolynomialFeatures(degree = degree)),</span><br><span class="line">        (<span class="string">"std"</span>, StandardScaler()),</span><br><span class="line">        (<span class="string">"reg"</span>, LinearRegression())</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span>(<span class="params">X, y, degree</span>):</span></span><br><span class="line">    train_mse = []</span><br><span class="line">    test_mse = []</span><br><span class="line">    X_train, X_test, y_train, y_test = train_test_split(X, y)</span><br><span class="line">    poly_reg = get_poly_reg(degree)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="built_in">len</span>(X) + <span class="number">1</span>):</span><br><span class="line">        poly_reg.fit(X_train[:i], y_train[:i])</span><br><span class="line">        train_pred = poly_reg.predict(X_train[:i])</span><br><span class="line">        test_pred = poly_reg.predict(X_test)</span><br><span class="line">        train_mse.append(np.mean(np.square(train_pred - y_train[:i])))</span><br><span class="line">        test_mse.append(np.mean(np.square(test_pred - y_test)))</span><br><span class="line">        </span><br><span class="line">    plt.plot(np.arange(<span class="number">2</span>, <span class="built_in">len</span>(X)+<span class="number">1</span>), train_mse, label=<span class="string">"train"</span>)</span><br><span class="line">    plt.plot(np.arange(<span class="number">2</span>, <span class="built_in">len</span>(X)+<span class="number">1</span>), test_mse, label=<span class="string">"test"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.axis([<span class="number">0</span>,<span class="number">100</span>,<span class="number">0</span>,<span class="number">5</span>])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>这次我们把目标函数换成二次函数。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X = np.random.uniform(-<span class="number">3</span>,<span class="number">3</span>,size=<span class="number">100</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">y = <span class="number">0.5</span> * X**<span class="number">2</span> + X + <span class="number">4</span> + np.random.normal(<span class="number">0</span>,<span class="number">1</span>,size = <span class="number">100</span>).reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>degree = 1</p>
<p>随着样本数量的增加 test 的误差在减小，train 的误差在增加，而当样本到了一定程度后，两者也没有保持在一个较小的程度上。这时说明模型欠拟合。</p>
<p><img src="https://z3.ax1x.com/2021/10/13/5u1WSP.png" alt=""></p>
<p>degree = 2</p>
<p><img src="https://z3.ax1x.com/2021/10/13/5uQx3V.png" alt=""></p>
<p>随着样本数量的增加 test 的误差在减小，train 的误差在增加，而当样本到了一定程度后，两者基本<code>持平</code>，保持在一个较小的程度上。这时模型已经拟合。</p>
<p>degree = 10</p>
<p><img src="https://z3.ax1x.com/2021/10/13/5ul2KU.png" alt=""></p>
<p>随着样本的增加 test 的误差在减小，train 的误差在增加，但当样本到了一定程度后，在 train 上的误差要比在 test 上的误差小得多，这时就要注意是不是过拟合了。</p>
<p>degree = 100</p>
<p><img src="https://z3.ax1x.com/2021/10/13/5ulxIA.png" alt=""></p>
<p>此时 test 上的误差已经飙到天上去了，妥妥的过拟合。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在训练数据集上表现良好，却在测试数据集上表现差劲的就是<code>过拟合</code>，这时候要降低参数数量。</p>
<p>而在训练数据集上表现就不尽人意的有可能是<code>欠拟合</code>（也有可能是模型压根不对等问题），这时候可以试试增大模型，增加参数数量。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/27/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/27/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/" class="post-title-link" itemprop="url">多项式回归</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-27 14:09:13" itemprop="dateCreated datePublished" datetime="2021-09-27T14:09:13+08:00">2021-09-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-10-19 19:48:21" itemprop="dateModified" datetime="2021-10-19T19:48:21+08:00">2021-10-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-Learning/" itemprop="url" rel="index"><span itemprop="name">Deep Learning</span></a>
                </span>
            </span>

          
            <span id="/2021/09/27/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/" class="post-meta-item leancloud_visitors" data-flag-title="多项式回归" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/09/27/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/09/27/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h2><p>如果你的数据比直线更复杂怎么办？例如抛物线。显然 <a href="/2021/09/13/线性回归">线性回归</a> 无法胜任这个工作，但我们只需要稍加修改，将每个特征的幂次方作为一个新特征即可，大致与<code>线性回归</code>类似，不过是多元一次和多元多次的区别。</p>
<p>线性回归假设目标拟合曲线函数为$y = w_1x_1 + w_2x_2 + w_3x_3 + … + b$，其中 $w_n$ 为系数 $x_n$ 为特征。</p>
<p>而多项式回归假设目标拟合曲线为$y = w_1x_1^n + w_2x_1^{n-1}x_2 + w_3x_1^{n-2}x_2^2 + … + w_nx_2^n$，这里出于简便只写了两个未知数的情况。</p>
<p><br></p>
<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>这里我用的是三次函数的图像外加了点噪声，用<code>线性回归</code>肯定是拟合不了的。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">x = np.arange(-<span class="number">10</span>, <span class="number">10</span>, <span class="number">0.1</span>)</span><br><span class="line">y = <span class="number">2.6</span> * x ** <span class="number">3</span> - <span class="number">3.14</span> * x ** <span class="number">2</span> - <span class="number">8.8</span> * x + np.random.normal(<span class="number">0</span>, <span class="number">700</span>, (<span class="number">200</span>, ))</span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://z3.ax1x.com/2021/09/27/4RC9un.png" alt=""></p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X = x.reshape([-<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">X = np.hstack([X ** <span class="number">3</span>, X ** <span class="number">2</span>, X])</span><br><span class="line">X_b = np.hstack([np.ones([<span class="built_in">len</span>(y), <span class="number">1</span>]), X])</span><br><span class="line"><span class="comment"># X [200, 3]</span></span><br><span class="line"><span class="built_in">print</span>(X.shape)</span><br></pre></td></tr></tbody></table></figure>
<p>如算法思想所述，梯度下降的代码是没有改变的，只是添加了特征的幂指数作为额外的特征值。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">J</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.mean((X_b.dot(theta) - y) ** <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">DJ</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">    <span class="keyword">return</span> X_b.T.dot((X_b.dot(theta) - y)) * <span class="number">2</span> / <span class="built_in">len</span>(y);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradient_descent</span>(<span class="params">X_b, y, theta, eta = <span class="number">0.01</span>, n_iters = <span class="number">1e4</span>, epsilon = <span class="number">1e-6</span></span>):</span></span><br><span class="line">    i_iter = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> i_iter &lt; n_iters:</span><br><span class="line">        gradient = DJ(X_b, y, theta)</span><br><span class="line">        last_theta = theta</span><br><span class="line">        theta = theta - eta * gradient</span><br><span class="line">        <span class="keyword">if</span> np.<span class="built_in">abs</span>(J(X_b, y, theta) - J(X_b, y, last_theta)) &lt; epsilon:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        i_iter += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> theta</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">initial_theta = np.zeros(X_b.shape[<span class="number">1</span>])</span><br><span class="line">theta = gradient_descent(X_b, y, initial_theta, eta = <span class="number">1e-6</span>, n_iters = <span class="number">1e5</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>得出 theta = array([-12.65120346,   2.89719563,  -3.12234806, -15.72650818])</p>
<p>也基本对应了我预设的函数系数[2.6, -3.14, -8.8]</p>
<p>注：theta 每一项分别对应了截距，$x^3$ 的系数，$x^2$ 的系数，$x$ 的系数。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pred_y = theta[<span class="number">1</span>] * x ** <span class="number">3</span> + theta[<span class="number">2</span>] * x ** <span class="number">2</span> + theta[<span class="number">3</span>] * x + theta[<span class="number">0</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x, pred_y, color = <span class="string">"r"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://z3.ax1x.com/2021/09/27/4RPGd0.png" alt=""></p>
<p><br></p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>需要注意的是多项式化是成<code>阶乘式</code>的增长，比指数爆炸更可怕！</p>
<p>$\frac{(n + d)!}{d!n!}$，其中 n 为原本特征数，d 为最高次数。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PolynomialRegression</span>:</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, degree</span>):</span></span><br><span class="line">        self.degree = degree</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X, y, eta = <span class="number">0.01</span>, n_iters = <span class="number">1e4</span>, epsilon = <span class="number">1e-6</span></span>):</span></span><br><span class="line">        self.X = self._getPolynomialFeatures(X, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), self.degree)</span><br><span class="line">        </span><br><span class="line">        initial_theta = np.zeros([self.X.shape[<span class="number">1</span>]])</span><br><span class="line">        theta = self._gradient_descent(self.X, y, initial_theta, eta, n_iters, epsilon)</span><br><span class="line">        self.theta = theta</span><br><span class="line">        self.coefficient = theta[<span class="number">1</span>:]</span><br><span class="line">        self.intercept = theta[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 多项式化</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_getPolynomialFeatures</span>(<span class="params">self, X, start, col_val, degree</span>):</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">X, result, start, col_val, degree</span>):</span></span><br><span class="line">            result.append(col_val)</span><br><span class="line">            <span class="keyword">if</span>(degree == <span class="number">0</span>):</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(start, X.shape[<span class="number">1</span>]):</span><br><span class="line">                dfs(X, result, start, col_val * X[:, i].reshape([-<span class="number">1</span>, <span class="number">1</span>]), degree - <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        result = []</span><br><span class="line">        dfs(X, result, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), degree)</span><br><span class="line">        <span class="keyword">return</span> np.squeeze(np.array(result), -<span class="number">1</span>).T</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        X_b = self._getPolynomialFeatures(X, <span class="number">0</span>, np.ones([<span class="built_in">len</span>(X), <span class="number">1</span>]), self.degree)</span><br><span class="line">        y_pred = X_b.dot(self.theta)</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">self, X, y</span>):</span></span><br><span class="line">        y_pred = self.predict(X)</span><br><span class="line">        <span class="keyword">return</span> np.mean((y - y_pred) ** <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_gradient_descent</span>(<span class="params">self, X_b, y, theta, eta, n_iters, epsilon</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">J</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">            <span class="keyword">return</span> np.mean((X_b.dot(theta) - y) ** <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">DJ</span>(<span class="params">X_b, y, theta</span>):</span></span><br><span class="line">            <span class="keyword">return</span> X_b.T.dot((X_b.dot(theta) - y)) * <span class="number">2</span> / <span class="built_in">len</span>(y);</span><br><span class="line">        </span><br><span class="line">        i_iter = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">        <span class="keyword">while</span> i_iter &lt; n_iters:</span><br><span class="line">            gradient = DJ(X_b, y, theta)</span><br><span class="line">            last_theta = theta</span><br><span class="line">            theta = theta - eta * gradient</span><br><span class="line">            <span class="keyword">if</span> np.<span class="built_in">abs</span>(J(X_b, y, theta) - J(X_b, y, last_theta)) &lt; epsilon:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            i_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> theta</span><br></pre></td></tr></tbody></table></figure>
<p><br></p>
<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">poly_reg = PolynomialRegression(<span class="number">3</span>)</span><br><span class="line">poly_reg.fit(x.reshape([-<span class="number">1</span>, <span class="number">1</span>]), y, eta = <span class="number">1e-6</span>, n_iters = <span class="number">1e5</span>)</span><br><span class="line"></span><br><span class="line">theta = poly_reg.theta</span><br><span class="line">pred_y = theta[<span class="number">3</span>] * x ** <span class="number">3</span> + theta[<span class="number">2</span>] * x ** <span class="number">2</span> + theta[<span class="number">1</span>] * x + theta[<span class="number">0</span>]</span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.plot(x, pred_y, color = <span class="string">"r"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></tbody></table></figure>
<p>结果如出一辙。</p>
<p><img src="https://z3.ax1x.com/2021/09/28/4fChIP.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/09/25/Navigation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/images/head-icon.jpg">
      <meta itemprop="name" content="紫梦沁香">
      <meta itemprop="description" content="如果说我看得比别人更远些，那是因为我站在巨人的肩膀上">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="紫梦沁香">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/25/Navigation/" class="post-title-link" itemprop="url">Navigation</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-09-25 16:50:57" itemprop="dateCreated datePublished" datetime="2021-09-25T16:50:57+08:00">2021-09-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-12-17 19:54:06" itemprop="dateModified" datetime="2021-12-17T19:54:06+08:00">2021-12-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Android/" itemprop="url" rel="index"><span itemprop="name">Android</span></a>
                </span>
            </span>

          
            <span id="/2021/09/25/Navigation/" class="post-meta-item leancloud_visitors" data-flag-title="Navigation" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/09/25/Navigation/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/09/25/Navigation/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><p>一个APP不可能只有一个页面吧，这时候就需要 Navigation 和 Fragment 来帮助我们切换页面。效果图如下。</p>
<p><img src="https://z3.ax1x.com/2021/09/25/4shGLT.gif" alt=""></p>
<p>Fragment 生命周期如下图所示。</p>
<p><img src="https://z3.ax1x.com/2021/09/25/4yVf4U.png" alt=""></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/09/25/Navigation/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="紫梦沁香"
      src="/uploads/images/head-icon.jpg">
  <p class="site-author-name" itemprop="name">紫梦沁香</p>
  <div class="site-description" itemprop="description">如果说我看得比别人更远些，那是因为我站在巨人的肩膀上</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="sidebar-button motion-element"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:1149911598@qq.com" title="E-Mail → mailto:1149911598@qq.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">紫梦沁香</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'xxQvJd4TcJMGK327OtwyS41T-gzGzoHsz',
      appKey     : 'GJqvYfNtvELk0Vvow1MAQo5i',
      placeholder: "",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
